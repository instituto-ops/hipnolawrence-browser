import asyncio
import os
import sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from hipnolawrence.core.browser import BrowserManager
from hipnolawrence.core.brain import Brain
from hipnolawrence.core.vision import VisionManager
from hipnolawrence.core.vision_ocr import VisionOCR

async def main():
    print("üß† Inicializando o Copiloto Estrat√©gico HipnoLawrence...")
    browser = BrowserManager()
    brain = Brain()
    vision = VisionManager()
    ocr = VisionOCR()

    print("üåê Acordando o navegador persistente...")
    await browser.launch()
    print("‚úÖ Sistema pronto. Modo Chatbot ativado.")

    chat_history = [] # Mem√≥ria de curto prazo

    while True:
        user_input = await asyncio.get_event_loop().run_in_executor(
            None, input, "\nüë®üíº Maestro: "
        )

        if user_input.lower() in ["sair", "exit", "quit"]:
            print("üõë Desligando o sistema...")
            await browser.close()
            break

        if not user_input.strip():
            continue

        # Formata o hist√≥rico (mant√©m apenas as √∫ltimas 4 intera√ß√µes para n√£o estourar o contexto do LLM local)
        history_text = "\n".join(chat_history[-8:])
        
        print("üß† Pensando...")
        action = brain.process_command(user_input, history=history_text)
        intent = action.get("intent", "UNKNOWN")
        args = action.get("args", {})

        # Atualiza hist√≥rico com a a√ß√£o do agente
        chat_history.append(f"Usu√°rio: {user_input}")
        chat_history.append(f"HipnoLawrence (Inten√ß√£o {intent}): {args}")

        try:
            if intent == "REPLY":
                # Modo Conversacional
                resposta = args.get("text", "N√£o consegui formular uma resposta.")
                print(f"\nü§ñ HipnoLawrence: {resposta}\n")

            elif intent == "NAVIGATE":
                url = args.get("url")
                if url:
                    print(f"ü§ñ HipnoLawrence: Navegando para {url}...")
                    await browser.goto(url)

            elif intent == "CLICK" or intent == "TYPE":
                target = args.get("target", "")
                text_to_type = args.get("text", "")
                
                print(f"üëÅÔ∏è Escaneando a tela em busca de '{target}'...")
                screenshot_name = "temp_action.png"
                await browser.take_screenshot(screenshot_name)
                screenshot_path = os.path.abspath(os.path.join("data", "screenshots", screenshot_name))
                
                elements = ocr.extract_elements(screenshot_path)
                target_found = False
                
                for el in elements:
                    text_el = el.get("text", "")
                    if target.lower() in text_el.lower() and len(text_el.strip()) > 1:
                        cx = el['x'] + (el['width'] / 2)
                        cy = el['y'] + (el['height'] / 2)
                        
                        await browser.click_coordinates(cx, cy)
                        target_found = True
                        
                        if intent == "TYPE":
                            print(f"‚å®Ô∏è Digitando: '{text_to_type}'...")
                            # Usa o teclado do Playwright para digitar no local clicado
                            await browser.page.keyboard.type(text_to_type, delay=50) # Delay simula digita√ß√£o humana
                            
                        else:
                            print(f"üéØ Cliquei em '{target}'.")
                        break
                
                if not target_found:
                    print(f"ü§ñ HipnoLawrence: N√£o encontrei '{target}' na tela para interagir.")

            elif intent == "ASK_VISION":
                question = args.get("question", "Descreva esta imagem.")
                print("üëÅÔ∏è Analisando visualmente...")
                screenshot_name = "temp_vision.png"
                await browser.take_screenshot(screenshot_name)
                screenshot_path = os.path.abspath(os.path.join("data", "screenshots", screenshot_name))
                
                answer = vision.analyze_image(screenshot_path, question)
                print(f"\nü§ñ HipnoLawrence (Vis√£o): {answer}\n")

            elif intent == "EXIT":
                print("ü§ñ HipnoLawrence: At√© logo, Maestro!")
                await browser.close()
                break

            else:
                print(f"ü§ñ HipnoLawrence: A√ß√£o interna n√£o reconhecida ({intent}).")

        except Exception as e:
            print(f"‚ùå Erro de execu√ß√£o f√≠sica: {e}")

if __name__ == "__main__":
    asyncio.run(main())
